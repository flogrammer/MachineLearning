{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi Layer Feedforward Neural Network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(1)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from help_functions import dataset_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aufbau des MLNN:\n",
    "Zuerst laden wir den Datensatz. Wir können die Funktion `Dataset Regression` verwenden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10a7300f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "n_samples = 400 # number of samples \n",
    "x1, y = dataset_regression(n_samples)\n",
    "plt.scatter(x1[:,0], y[:,0] , s=40, cmap=plt.cm.Spectral)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zu Beginn versuchen wir eine lineare Abbildung zwischen Eingang $ x_1 $ und Ausgang $ y $ zuerstellen d.h. ohne zusätzliche versteckte schichten hinzuzufügen. Abbildung 1 zeigt dieses Netzwerk.\n",
    "\n",
    "<img src=\"img/NNKit1.png\" style=\"width:350px;height:200;\">\n",
    "<caption><center> <u> **Abbildung 1** </u>: **Lineares Modell mit keiner versteckten Ebene**<br> </center></caption>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ihre erste Aufgabe **die Gewichte zu Initalisieren**.\n",
    "> **Hinweis:** Gewichte sollen verschieden voneinander, zufällig, gleichverteilt und klein sein. Sie können Befehl `W = 0.01 * np.random.randn(n_x,n_y)` wobei `n_x` ist die Anzahl von Eingang + 1 und `n_y` ist die Anzahl von Ausgang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_x = 2\n",
    "n_y = 1\n",
    "W = 0.01 * np.random.randn(n_x,n_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Beziehung zwischen Eingang und Ausgang ist linear\n",
    "$$ y_{pred} = \\sum_i w_i*x_i  $$  \n",
    "Ihre zweite Aufgabe besteht darin, zu versuchen, **diese Gleichung mit `numpy` zu implementieren** und den Code auszuführen, um das Ergebnis zu sehen.\n",
    "> **Hinweis:** $  \\sum_i w_i*x_i  $ diese Gleichung könnte als Skalarprodukt zwischen Gewicht Vektor und Eingangsvektor. Sie können Befehl `np.dot(X,W)` um Skalarprudokt mit `numpy` implementieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bias\n",
    "x0 = np.ones((x1.shape[0],1))\n",
    "# Conatenate the bias and the input in one vector x \n",
    "X= np.concatenate([x0,x1],axis=1)\n",
    "\n",
    "# TODO: the output of the network\n",
    "y_pred = np.dot(X,W)\n",
    "\n",
    "\n",
    "# Don't change the following code\n",
    "plt.scatter(x1[:,0], y[:,0] , s=40, cmap=plt.cm.Spectral)\n",
    "plt.plot(x1[:,0],y_pred[:,0],'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ihr erstes Modell passt möglicherweise nicht sehr gut zu den Daten. Suchen Sie nach einer guten Lösung für die optimalen Gewichte, um ein besseres Modell zu erhalten. Lassen Sie uns gemeinsam den Lernprozess Backpropagation durchführen. **zunächst sollte Fehlerfunktion implementiert werden** im Skript von `ML1` wurde die folgende Fehlerfunktion betrachtet,\n",
    "$$E(W) = \\frac{1}{2} \\sum (y - y_{pred})^2$$\n",
    "wobei,\n",
    "* $y$ ist  der richtige Ausgang (Target) und\n",
    "* $y_{pred}$ ist der Ausgang des Modells (Prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate the loss function\n",
    "E = 1/2* np.square(np.sum(y-y_pred))\n",
    "print('The Loss function is equal: ', E)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Versuchen wir nun, diesen Fehler zu minimieren und die Gewichte anzupassen. Diese Änderung sollte nach dem Gradienten erfolgen.\n",
    "$$\\Delta w_{i} = -\\eta \\frac{\\partial E}{\\partial w_{i}}$$\n",
    "wobei\n",
    "* $\\eta$ ist Lernrate\n",
    "* $ i \\in {0,1} $\n",
    "$$\\begin{split}\n",
    "E(W)&  = \\frac{1}{2} \\sum (y - y_{pred})^2\\\\\n",
    " & = \\frac{1}{2} \\sum (y - \\sum_i w_ix_i)^2\n",
    "\\end{split}$$\n",
    "\n",
    "Die partielle Ableitung nach $ w_i $ lautet\n",
    "$$\\begin{split}\n",
    "\\frac{\\partial E}{\\partial w_{i}}&  = (y_{pred} - y)x_i\n",
    "\\end{split}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate:\n",
    "eta = 0.01\n",
    "\n",
    "# Gradient Decent Todo\n",
    "dW = -eta *np.dot((y_pred - y).T,X)\n",
    "\n",
    "print('The change in wights:')\n",
    "print('dw0 = ', dW[0,0])\n",
    "print('dw1 = ', dW[0,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir können nun diese Ergebnisse verwenden, um die Gewichtungen zu aktualisieren. Implementieren Sie die folgende Gleichung,\n",
    "$$w_i = w_i + \\Delta w_{i} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Update the weights\n",
    "W = W + dW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt schreiben wir den ganzen Code in einem Stück,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LinearModel(x1,y, n_Iteration = 100000):\n",
    "    # step 0: Initialize the weights\n",
    "    n_x = 2\n",
    "    n_y = 1\n",
    "    W = 0.01 * np.random.randn(n_x,n_y)\n",
    "    costs = []\n",
    "    # step1: define the bias and Conatenate the bias and the input x1 in one vector X \n",
    "    x0 = np.ones((x1.shape[0],1))\n",
    "    X= np.concatenate([x0,x1],axis=1)\n",
    "    for i in range(n_Iteration):\n",
    "        \n",
    "        \n",
    "        # step2: TODO: the output of the network\n",
    "        y_pred = np.dot(X,W)\n",
    "        \n",
    "        # step3: TODO: calculate the loss function\n",
    "        E = 1/2* (np.sum(np.square(y-y_pred)))\n",
    "        # Record the costs\n",
    "        if i % 100 == 0:\n",
    "            costs.append(E)\n",
    "        \n",
    "        # Print the cost every 100 training examples\n",
    "        if  i % 100 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, E))\n",
    "        \n",
    "        # step4: TODO Gradient Decent \n",
    "        eta = 0.0001\n",
    "#       print(X)\n",
    "        dW = eta * np.dot(X.T,(y_pred - y))\n",
    "        # step5 : TODO Update the weights\n",
    "        W = W - dW\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change the following code only run it\n",
    "W = LinearModel(x1,y, n_Iteration = 1000)\n",
    "\n",
    "x0 = np.ones((x1.shape[0],1))\n",
    "X= np.concatenate([x0,x1],axis=1)\n",
    "# Make a prediction \n",
    "y_pred= np.dot(X,W)\n",
    "\n",
    "# Plot the result\n",
    "plt.scatter(x1[:,0], y[:,0] , s=40, cmap=plt.cm.Spectral)\n",
    "plt.plot(x1[:,0],y_pred[:,0],'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation Function:\n",
    "Im letzten Beispiel haben wir gesehen, dass ein lineares Modell nicht gut in die Daten passt. Daher möchten wir nun dem Modell durch eine Aktivierungsfunktion eine Nichtlinearität hinzufügen. Abbildung 2 zeigt dieses Netzwerk.\n",
    "\n",
    "<img src=\"img/NNKit2-2.png\" style=\"width:350px;height:200;\">\n",
    "<caption><center> <u> **Abbildung 2** </u>: **Nichtlineares Modell mit einer versteckten Schicht**<br> </center></caption>\n",
    "\n",
    "Im Skript von `ML1` wurden mehrere Aktivierungsfunktionen betrachtet. Eine davon ist **Sigmoid** Funktion, die durch die folgende Gleichung beschrieben werden kann.\n",
    "\n",
    "$$\\sigma = f(x) = \\frac{1}{1+e^{x}}$$\n",
    "\n",
    "Jetzt ist Ihre Aufgabe die Sigmoid Funktion mit `python` zu implemtieren, weil wir in Forward Propagation verwenden sollten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    # TODO: \n",
    "    s = 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    return s "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Berechnen Sie den Gradienten der Sigmoid Funktion in Bezug auf ihren Eingang x, damit Sie ihn in Backpropagation benutzen können.\n",
    "$$\\frac{\\partial  \\sigma}{\\partial x} =  \\sigma(1- \\sigma)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    \n",
    "    # TODO:\n",
    "    s = sigmoid(x)\n",
    "    ds = s*(1-s)\n",
    "    \n",
    "    return ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisierung der Parameter\n",
    "> **Hinweis:** Gewichte sollen verschieden voneinander, zufällig, gleichverteilt und klein sein. Sie können Befehl `W = 0.01 * np.random.randn(n_x,n_y)` wobei `n_x` ist die Anzahl von Eingang + 1 (wegen Bias) und `n_y` ist die Anzahl von Ausgang. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parameter_initialize(n_x= 1, n_h = 1, n_y=1):\n",
    "    # TODO : initialize the weights\n",
    "    # Input layer : W1 = [w01 w11]\n",
    "    W1 = 0.01 * np.random.randn(n_x+1,n_h)\n",
    "    # Hidden layer : W2 = [w02 w12]\n",
    "    W2 = 0.01 * np.random.randn(n_h+1,n_y)\n",
    "    # save these parameters to use them again in Backward Propagation \n",
    "    parameters= {\"W1\": W1,\n",
    "                 \"W2\": W2}\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation:\n",
    "Der Eingang der versteckten Schicht ist\n",
    "$$ \\begin{split} Z &=  \\sum_{i=0}^1 w_{i,1}*x_{i,1} \\\\\n",
    "                          & = \\begin{bmatrix}x_{0} & x_{1} \\end{bmatrix} \\begin{bmatrix} w_{0,1} \\\\ w_{1,1} \\end{bmatrix} \\\\\n",
    "                          & = X^T W_1 \n",
    "                          \\end{split}$$\n",
    "\n",
    "wobei\n",
    "* $x_0 = 1$\n",
    "\n",
    "Der Ausgang der versteckten Schicht ist\n",
    "$$ a_1 = \\text{sigmoid}(Z) $$ \n",
    "\n",
    "Der Ausgang des Modells ist\n",
    "$$ \\begin{split} y_{pred} & =   \\sum_{i=0}^1 w_{i,2}a_{i}\\\\  \n",
    "                          & = \\begin{bmatrix}a_{0} & a_{1} \\end{bmatrix} \\begin{bmatrix} w_{0,2} \\\\ w_{1,2} \\end{bmatrix} \\\\\n",
    "                          & = A^T W_2\n",
    "                          \\end{split}$$\n",
    "\n",
    "wobei\n",
    "* $a_0 = 1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(X,parameters):\n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    # TODO: Implement Forward Propagation to calculate ypred\n",
    "    Z = np.dot(X,W1)\n",
    "    a1 = sigmoid(Z)\n",
    "    # concatenate a0 and a1 in one vector \n",
    "    a0 = np.ones((a1.shape[0],1))\n",
    "    A= np.concatenate([a0,a1],axis=1)\n",
    "    # TODO: the Output of your Model\n",
    "    ypred = np.dot(A,W2)\n",
    "    \n",
    "    # save  some parameters to use them again in Backward Propagation\n",
    "\n",
    "    Memory = {\"Z\": Z,\n",
    "              \"A\" : A,\n",
    "              \"ypred\": ypred}\n",
    "    \n",
    "    return ypred, Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fehlerfunktion:\n",
    "Der Fehler ist defienret durch\n",
    "$$ F = y - y_{pred} $$\n",
    "\n",
    "und die Fehlerfunktion\n",
    "$$E(W) = \\frac{1}{2} \\sum (y - y_{pred})^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(Memory, y):\n",
    "    ypred = Memory[\"ypred\"]\n",
    "    # TODO: Compute the cost\n",
    "    E = 1/2* (np.sum(np.square(y-ypred)))  \n",
    "    \n",
    "    E = np.squeeze(E)     # makes sure cost is the dimension we expect.  \n",
    "    \n",
    "    return E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation:\n",
    "\n",
    "<img src=\"img/backpropagation.gif\" style=\"width:500px;height:300;\">\n",
    "<caption><center> <u> **Abbildung 2** </u>: **Nichtlineares Modell mit einer versteckten Schicht**<br> </center></caption>\n",
    "\n",
    "\n",
    "Die Fehlerfunktion kann durch die Gewichtsänderung minimiert werden\n",
    "$$E(W) = \\frac{1}{2} \\sum (y - A^T W_2)^2$$\n",
    "\n",
    "Diese Änderung soll nach dem Gradienten sein.\n",
    "\n",
    "Die partielle Ableitung der Fehlerfunktion nach Gewichtungen in der versteckten Schicht $ w_{i,2} $\n",
    "$$ dW_2 = \\begin{bmatrix} dw_{0,2} \\\\ dw_{1,2} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial E(W)}{\\partial w_{0,2}}\\\\ \\frac{\\partial E(W)}{\\partial w_{1,2}} \\end{bmatrix}  = \\begin{bmatrix} -Fa_{0}\\\\ -Fa_{1} \\end{bmatrix} = -A^TF$$\n",
    "\n",
    "\n",
    "Die partielle Ableitung der Fehlerfunktion nach Ausgang der versteckten Schicht ist  $a_{1} $\n",
    "$$ dE =\\frac{\\partial E}{\\partial a_{1}}  = -w_{1,2}F  $$\n",
    "\n",
    "\n",
    "Wie bereits erwähnt, ist die **Sigmoid-Funktion** $\\sigma $ als die Aktivierungsfunktion verwendet wurde. Die partielle Ableitungen des Ausgangs der versteckten Schicht nach den Ausgang der Eingang Schicht $Z $\n",
    "$$\\begin{split}\n",
    "da_1 = \\frac{\\partial a_1}{\\partial Z} & = \\sigma( Z)(1-\\sigma( Z))\\\\\n",
    "& = a_1(1-a_1)\n",
    "\\end{split}$$\n",
    "\n",
    "Die partielle Ableitungen des Ausgang der Eingangsschicht $Z$ nach  den Gewichtungen in der Eingangsschicht\n",
    "$$ dZ = \\begin{bmatrix} z_0 \\\\  z_1  \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial Z}{\\partial w_{0,1}} \\\\  \\frac{\\partial Z}{\\partial w_{1,1}} \\end{bmatrix} = \\begin{bmatrix}  x_0 \\\\ x_1 \\end{bmatrix}$$\n",
    "\n",
    "\n",
    "\n",
    "Die partiellen Ableitungen der Fehlerfunktion nach den Gewichtungen in der Eingabeschicht können nun mit der **Kettenregel** berechnet werden **\n",
    "$$ dW_1 = \\begin{bmatrix} dw_{0,1} \\\\ dw_{1,1} \\end{bmatrix} = \\begin{bmatrix} \\frac{\\partial E}{\\partial w_{0,1}} \\\\ \\frac{\\partial E}{\\partial w_{1,1}} \\end{bmatrix} = dE  da_1 dZ\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, Memory, X, y):\n",
    "\n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    W1 = parameters[\"W1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    \n",
    "    # Second, retrieve A1 and ypred from the dictionary \"Memory\".    \n",
    "    Z = Memory[\"Z\"]\n",
    "    A = Memory[\"A\"]\n",
    "    ypred = Memory[\"ypred\"]\n",
    "\n",
    "    \n",
    "    # Backward propagation: calculate dW2 and dW1  \n",
    "    F=  y - ypred\n",
    "    dW2= - np.dot(A.T,F) \n",
    "    dE = - W2[1,0]*F\n",
    "    \n",
    "    da1 = sigmoid_derivative(Z)\n",
    "    dZ = X\n",
    "    dW1= np.dot(X.T,dE*da1)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # save the gradient to use them to update the weights\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"dW2\": dW2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hauptprogramm\n",
    "Wir haben bereits alle notwendigen Funktionen implementiert, um unser Modell zu erstellen und zu trainieren. Nun wollen wir  all diese Funktionen in einem Hauptprogramm durchführen. \n",
    "* Schritt 1: Definieren Sie die Trainingsdaten\n",
    "* Schritt 2: Initialisieren Sie die Gewichte\n",
    "* Schritt 3: Trainieren Sie Ihre Modell\n",
    "   * Forward Propagation \n",
    "   * Berechnen der Fehlerfunktion\n",
    "   * Backward Propagation\n",
    "   * Aktualisierung der Gewichte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs= []\n",
    "x0 = np.ones((x1.shape[0],1))\n",
    "X= np.concatenate([x0,x1],axis=1)\n",
    "\n",
    "parameters = parameter_initialize()\n",
    "W1 = parameters[\"W1\"]\n",
    "W2 = parameters[\"W2\"]\n",
    "for i in range(4000):\n",
    "    ypred, Memory = forward_propagation(X, parameters)\n",
    "    E = compute_cost(Memory, y)\n",
    "    if i % 100 == 0:\n",
    "        costs.append(E)\n",
    "        # Print the cost every 100 training examples\n",
    "        print (\"Cost after iteration %i: %f\" %(i, E))\n",
    "            \n",
    "        \n",
    "    # Gradient Decent \n",
    "    grads = backward_propagation(parameters, Memory, X, y)\n",
    "    dW1 = grads[\"dW1\"]\n",
    "    dW2 = grads[\"dW2\"]\n",
    "    \n",
    "    eta = 0.001\n",
    "    # step5 : TODO Update the weights\n",
    "    W1 = W1 - eta*dW1\n",
    "    W2 = W2 - eta*dW2\n",
    "    \n",
    "    parameters= {\"W1\": W1,\n",
    "                 \"W2\": W2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the result\n",
    "y_pred = Memory[\"ypred\"]\n",
    "plt.scatter(x1[:,0], y[:,0] , s=40, cmap=plt.cm.Spectral)\n",
    "plt.plot(x1[:,0],y_pred[:,0],'red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
