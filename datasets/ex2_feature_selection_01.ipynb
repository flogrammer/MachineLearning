{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "data_values = dataframe.values # 768 samples, 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.     148.      72.    ...,    0.627   50.       1.   ]\n",
      " [   1.      85.      66.    ...,    0.351   31.       0.   ]\n",
      " [   8.     183.      64.    ...,    0.672   32.       1.   ]\n",
      " ..., \n",
      " [   5.     121.      72.    ...,    0.245   30.       0.   ]\n",
      " [   1.     126.      60.    ...,    0.349   47.       1.   ]\n",
      " [   1.      93.      70.    ...,    0.315   23.       0.   ]]\n",
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "print data_values\n",
    "print data_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n"
     ]
    }
   ],
   "source": [
    "feature_matrix = data_values[:,0:8]\n",
    "labels = data_values[:,8]\n",
    "\n",
    "print len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = feature_matrix[:450]\n",
    "train_labels = labels[:450]\n",
    "\n",
    "test_features = feature_matrix[450:]\n",
    "test_labels = labels[450:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python2.7/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "\n",
    "model.fit(train_features,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse von Model Naive Bayes\n",
      "[[142  80]\n",
      " [ 49  47]]\n",
      "('Klassifikationsfehler: ', 0.4056603773584906)\n",
      "('Guete: ', 0.5943396226415094)\n"
     ]
    }
   ],
   "source": [
    "result = model.predict(test_features)\n",
    "\n",
    "cfm = metrics.confusion_matrix(test_labels,result)\n",
    "\n",
    "#True Positive\n",
    "tp = cfm[0][0]\n",
    "#FalsePositive\n",
    "fp = cfm[0][1]\n",
    "#FalseNegative\n",
    "fn = cfm[1][0]\n",
    "#TrueNegative\n",
    "tn = cfm[1][1]\n",
    "\n",
    "print('Ergebnisse von Model Naive Bayes')\n",
    "print(cfm)\n",
    "\n",
    "klassifikationsfehler = float(fp + fn)/(tp+fp+tn+fn)\n",
    "print('Klassifikationsfehler: ', klassifikationsfehler)\n",
    "guete = float(tp + tn)/(tp+fp+tn+fn)\n",
    "print('Guete: ', guete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Gesund       0.74      0.64      0.69       222\n",
      "   Diabetes       0.37      0.49      0.42        96\n",
      "\n",
      "avg / total       0.63      0.59      0.61       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, result, target_names=['Gesund','Diabetes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  111.52   1411.887    17.605    53.108  2175.565   127.669     5.393\n",
      "   181.304]\n",
      "[[   6.   148.     0.    33.6   50. ]\n",
      " [   1.    85.     0.    26.6   31. ]\n",
      " [   8.   183.     0.    23.3   32. ]\n",
      " [   1.    89.    94.    28.1   21. ]\n",
      " [   0.   137.   168.    43.1   33. ]]\n",
      "preg\n",
      "plas\n",
      "test\n",
      "mass\n",
      "age\n"
     ]
    }
   ],
   "source": [
    "# feature selection with SelectKBest\n",
    "test = SelectKBest(score_func=chi2, k=5)\n",
    "fit = test.fit(feature_matrix, labels)\n",
    "# summarize scores\n",
    "numpy.set_printoptions(precision=3)\n",
    "print(fit.scores_)\n",
    "selected_features = fit.transform(feature_matrix)\n",
    "# summarize selected features\n",
    "print(selected_features[0:5,:])\n",
    "\n",
    "# show selected features\n",
    "for i, selected in enumerate(fit.get_support()):\n",
    "    if selected:\n",
    "        print names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train_features = selected_features[:450]\n",
    "selected_test_features = selected_features[450:]\n",
    "\n",
    "model2 = MultinomialNB()\n",
    "\n",
    "model2.fit(selected_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse von Model Naive Bayes\n",
      "[[138  84]\n",
      " [ 53  43]]\n",
      "('Klassifikationsfehler: ', 0.4308176100628931)\n",
      "('Guete: ', 0.5691823899371069)\n"
     ]
    }
   ],
   "source": [
    "result2 = model2.predict(selected_test_features)\n",
    "\n",
    "cfm = metrics.confusion_matrix(test_labels,result2)\n",
    "\n",
    "#True Positive\n",
    "tp = cfm[0][0]\n",
    "#FalsePositive\n",
    "fp = cfm[0][1]\n",
    "#FalseNegative\n",
    "fn = cfm[1][0]\n",
    "#TrueNegative\n",
    "tn = cfm[1][1]\n",
    "\n",
    "print('Ergebnisse von Model Naive Bayes')\n",
    "print(cfm)\n",
    "\n",
    "klassifikationsfehler = float(fp + fn)/(tp+fp+tn+fn)\n",
    "print('Klassifikationsfehler: ', klassifikationsfehler)\n",
    "guete = float(tp + tn)/(tp+fp+tn+fn)\n",
    "print('Guete: ', guete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Gesund       0.72      0.62      0.67       222\n",
      "   Diabetes       0.34      0.45      0.39        96\n",
      "\n",
      "avg / total       0.61      0.57      0.58       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, result2, target_names=['Gesund','Diabetes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  6.     33.6     0.627]\n",
      " [  1.     26.6     0.351]\n",
      " [  8.     23.3     0.672]\n",
      " [  1.     28.1     0.167]\n",
      " [  0.     43.1     2.288]]\n",
      "preg\n",
      "mass\n",
      "pedi\n"
     ]
    }
   ],
   "source": [
    "# feature selection RFE\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, 3)\n",
    "fit = rfe.fit(feature_matrix, labels)\n",
    "\n",
    "selected_features = fit.transform(feature_matrix)\n",
    "# summarize selected features\n",
    "print(selected_features[0:5,:])\n",
    "\n",
    "# show selected features\n",
    "for i, selected in enumerate(fit.support_):\n",
    "    if selected:\n",
    "        print names[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train_features = selected_features[:450]\n",
    "selected_test_features = selected_features[450:]\n",
    "\n",
    "model3 = MultinomialNB()\n",
    "\n",
    "model3.fit(selected_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse von Model Naive Bayes\n",
      "[[174  48]\n",
      " [ 59  37]]\n",
      "('Klassifikationsfehler: ', 0.33647798742138363)\n",
      "('Guete: ', 0.6635220125786163)\n"
     ]
    }
   ],
   "source": [
    "result3 = model3.predict(selected_test_features)\n",
    "\n",
    "cfm = metrics.confusion_matrix(test_labels,result3)\n",
    "\n",
    "#True Positive\n",
    "tp = cfm[0][0]\n",
    "#FalsePositive\n",
    "fp = cfm[0][1]\n",
    "#FalseNegative\n",
    "fn = cfm[1][0]\n",
    "#TrueNegative\n",
    "tn = cfm[1][1]\n",
    "\n",
    "print('Ergebnisse von Model Naive Bayes')\n",
    "print(cfm)\n",
    "\n",
    "klassifikationsfehler = float(fp + fn)/(tp+fp+tn+fn)\n",
    "print('Klassifikationsfehler: ', klassifikationsfehler)\n",
    "guete = float(tp + tn)/(tp+fp+tn+fn)\n",
    "print('Guete: ', guete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Gesund       0.75      0.78      0.76       222\n",
      "   Diabetes       0.44      0.39      0.41        96\n",
      "\n",
      "avg / total       0.65      0.66      0.66       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, result3, target_names=['Gesund','Diabetes']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age']\n",
      "[ 0.105  0.238  0.099  0.089  0.061  0.141  0.123  0.143]\n"
     ]
    }
   ],
   "source": [
    "# feature selection with Trees\n",
    "model = ExtraTreesClassifier()\n",
    "model.fit(feature_matrix, labels)\n",
    "\n",
    "print names[:-1]\n",
    "print model.feature_importances_\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = numpy.argsort(importances)[::-1]\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(feature_matrix.shape[1]), importances[indices],\n",
    "       color=\"r\", align=\"center\")\n",
    "plt.xticks(range(feature_matrix.shape[1]), indices)\n",
    "plt.xlim([-1, feature_matrix.shape[1]])\n",
    "plt.show()\n",
    "\n",
    "#plas, age, mass\n",
    "selected_indices = [1, 5, 7]\n",
    "selected_features = []\n",
    "for sample in range(len(feature_matrix)):\n",
    "    sample_features = []\n",
    "    for i in selected_indices:\n",
    "        sample_features.append(feature_matrix[sample, i])\n",
    "    selected_features.append(sample_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_train_features = selected_features[:450]\n",
    "selected_test_features = selected_features[450:]\n",
    "\n",
    "model4 = MultinomialNB()\n",
    "\n",
    "model4.fit(selected_train_features, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse von Model Naive Bayes\n",
      "[[186  36]\n",
      " [ 62  34]]\n",
      "('Klassifikationsfehler: ', 0.3081761006289308)\n",
      "('Guete: ', 0.6918238993710691)\n"
     ]
    }
   ],
   "source": [
    "result4 = model4.predict(selected_test_features)\n",
    "\n",
    "cfm = metrics.confusion_matrix(test_labels,result4)\n",
    "\n",
    "#True Positive\n",
    "tp = cfm[0][0]\n",
    "#FalsePositive\n",
    "fp = cfm[0][1]\n",
    "#FalseNegative\n",
    "fn = cfm[1][0]\n",
    "#TrueNegative\n",
    "tn = cfm[1][1]\n",
    "\n",
    "print('Ergebnisse von Model Naive Bayes')\n",
    "print(cfm)\n",
    "\n",
    "klassifikationsfehler = float(fp + fn)/(tp+fp+tn+fn)\n",
    "print('Klassifikationsfehler: ', klassifikationsfehler)\n",
    "guete = float(tp + tn)/(tp+fp+tn+fn)\n",
    "print('Guete: ', guete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "     Gesund       0.75      0.78      0.76       222\n",
      "   Diabetes       0.44      0.39      0.41        96\n",
      "\n",
      "avg / total       0.65      0.66      0.66       318\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, result3, target_names=['Gesund','Diabetes']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
