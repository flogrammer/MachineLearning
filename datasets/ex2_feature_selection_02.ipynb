{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_Dictionary(train_dir):\n",
    "    emails = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]\n",
    "    all_words = []       \n",
    "    for mail in emails:  \n",
    "        with open(mail) as m:\n",
    "            for i,line in enumerate(m):\n",
    "                if i == 2:\n",
    "                    words = line.split()\n",
    "                    all_words += words\n",
    "    #zählen der Wörter\n",
    "    dictionary = Counter(all_words)\n",
    "    list_to_remove = list(dictionary)\n",
    "    for item in list_to_remove:\n",
    "        #entfernt sonderzeichen und 1 zeichen\n",
    "        if item.isalpha() == False: \n",
    "            del dictionary[item]\n",
    "        elif len(item) == 1:\n",
    "            del dictionary[item]\n",
    "    dictionary = dictionary.most_common(700)\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(mail_dir, dictionary): \n",
    "    files = [os.path.join(mail_dir,fi) for fi in sorted(os.listdir(mail_dir))]\n",
    "    features_matrix = np.zeros((len(files),700))\n",
    "    docID = 0;\n",
    "    for fil in files:\n",
    "      with open(fil) as fi:\n",
    "        for i,line in enumerate(fi):\n",
    "          if i == 2:\n",
    "            words = line.split()\n",
    "            for word in words:\n",
    "              wordID = 0\n",
    "              for i,d in enumerate(dictionary):\n",
    "                if d[0] == word:\n",
    "                  wordID = i\n",
    "                  features_matrix[docID,wordID] = words.count(word)\n",
    "        docID = docID + 1     \n",
    "    return features_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a dictionary of words with its frequency\n",
    "train_dir = '/path/to/ling-spam/train-mails'\n",
    "dictionary = make_Dictionary(train_dir)\n",
    "#print(dictionary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prepare feature vectors per training mail and its labels\n",
    "\n",
    "train_labels = np.zeros(702)\n",
    "train_labels[351:702] = 1\n",
    "train_matrix = extract_features(train_dir, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('order', 1414), ('address', 1293), ('report', 1216), ('mail', 1127), ('send', 1079), ('language', 1072), ('email', 1051), ('program', 1001), ('our', 987), ('list', 935), ('one', 917), ('name', 878), ('receive', 826), ('money', 788), ('free', 762), ('work', 755), ('information', 677), ('business', 654), ('please', 652), ('university', 595), ('us', 564), ('day', 556), ('follow', 544), ('internet', 520), ('over', 511), ('http', 479), ('check', 472), ('call', 469), ('each', 466), ('include', 452), ('com', 448), ('linguistic', 442), ('number', 423), ('want', 420), ('letter', 419), ('need', 418), ('many', 412), ('here', 397), ('market', 395), ('start', 390), ('even', 386), ('fax', 383), ('form', 380), ('most', 377), ('first', 373), ('web', 366), ('service', 363), ('interest', 362), ('software', 352), ('remove', 349)]\n",
      "('address', 1293)\n",
      "('mail', 1127)\n",
      "('language', 1072)\n",
      "('email', 1051)\n",
      "('our', 987)\n",
      "('receive', 826)\n",
      "('money', 788)\n",
      "('free', 762)\n",
      "('business', 654)\n",
      "('please', 652)\n",
      "('university', 595)\n",
      "('day', 556)\n",
      "('internet', 520)\n",
      "('check', 472)\n",
      "('linguistic', 442)\n",
      "('market', 395)\n",
      "('remove', 349)\n",
      "('week', 344)\n",
      "('every', 332)\n",
      "('site', 320)\n",
      "('edu', 318)\n",
      "('english', 318)\n",
      "('product', 317)\n",
      "('bulk', 312)\n",
      "('offer', 297)\n",
      "('de', 272)\n",
      "('pay', 256)\n",
      "('million', 254)\n",
      "('sell', 251)\n",
      "('easy', 229)\n",
      "('income', 226)\n",
      "('today', 220)\n",
      "('company', 219)\n",
      "('advertise', 213)\n",
      "('cash', 204)\n",
      "('linguist', 198)\n",
      "('down', 196)\n",
      "('instruction', 164)\n",
      "('dollar', 158)\n",
      "('guarantee', 153)\n",
      "('linguistics', 153)\n",
      "('grammar', 133)\n",
      "('office', 132)\n",
      "('purchase', 125)\n",
      "('code', 119)\n",
      "('online', 104)\n",
      "('immediately', 97)\n",
      "('syntax', 89)\n",
      "('development', 81)\n",
      "('watch', 77)\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "\n",
    "sel = SelectKBest(mutual_info_classif, k=50)\n",
    "fit = sel.fit(train_matrix, train_labels)\n",
    "\n",
    "print dictionary[:50]\n",
    "\n",
    "# show selected features\n",
    "for i, selected in enumerate(fit.get_support()):\n",
    "    if selected:\n",
    "        print dictionary[i]\n",
    "\n",
    "train_matrix_new = fit.transform(train_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/sparse/compressed.py:130: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.indices) != 1 or np.rank(self.indptr) != 1:\n",
      "/usr/lib/python2.7/dist-packages/scipy/sparse/coo.py:200: VisibleDeprecationWarning: `rank` is deprecated; use the `ndim` attribute or function instead. To find the rank of a matrix see `numpy.linalg.matrix_rank`.\n",
      "  if np.rank(self.data) != 1 or np.rank(self.row) != 1 or np.rank(self.col) != 1:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training SVM and Naive bayes classifier and its variants\n",
    "\n",
    "model1 = LinearSVC()\n",
    "model2 = MultinomialNB()\n",
    "\n",
    "model1.fit(train_matrix_new,train_labels)\n",
    "model2.fit(train_matrix_new,train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(260, 700)\n",
      "(260, 50)\n"
     ]
    }
   ],
   "source": [
    "test_dir = '/path/to/ling-spam/test-mails'\n",
    "test_matrix = extract_features(test_dir, dictionary)\n",
    "test_labels = np.zeros(260)\n",
    "test_labels[130:260] = 1\n",
    "\n",
    "print test_matrix.shape\n",
    "\n",
    "test_matrix_new = sel.transform(test_matrix)\n",
    "print test_matrix_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ergebnisse von Model 2: Naive Bayes\n",
      "[[125   5]\n",
      " [ 16 114]]\n",
      "('Klassifikationsfehler: ', 0.08076923076923077)\n",
      "('Guete: ', 0.9192307692307692)\n"
     ]
    }
   ],
   "source": [
    "result1 = model1.predict(test_matrix_new)\n",
    "result2 = model2.predict(test_matrix_new)\n",
    "\n",
    "cfm2 = metrics.confusion_matrix(test_labels,result2)\n",
    "\n",
    "#True Positive\n",
    "tp = cfm2[0][0]\n",
    "#FalsePositive\n",
    "fp = cfm2[0][1]\n",
    "#FalseNegative\n",
    "fn = cfm2[1][0]\n",
    "#TrueNegative\n",
    "tn = cfm2[1][1]\n",
    "\n",
    "print('Ergebnisse von Model 2: Naive Bayes')\n",
    "#print(confusion_matrix(test_labels,result1))\n",
    "print(cfm2)\n",
    "\n",
    "klassifikationsfehler = float(fp + fn)/(tp+fp+tn+fn)\n",
    "print('Klassifikationsfehler: ', klassifikationsfehler)\n",
    "guete = float(tp + tn)/(tp+fp+tn+fn)\n",
    "print('Guete: ', guete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        Ham       0.89      0.96      0.92       130\n",
      "       Spam       0.96      0.88      0.92       130\n",
      "\n",
      "avg / total       0.92      0.92      0.92       260\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(test_labels, result2, target_names=['Ham','Spam']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fpr1, tpr1, thresholds1 = metrics.roc_curve(test_labels, result1, pos_label=0)\n",
    "\n",
    "# Print ROC curve\n",
    "plt.plot(tpr1,fpr1)\n",
    "plt.show()\n",
    "\n",
    "fpr2, tpr2, thresholds2 = metrics.roc_curve(test_labels, result2, pos_label=0)\n",
    "\n",
    "# Print ROC curve\n",
    "plt.plot(tpr2,fpr2)\n",
    "plt.show() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
