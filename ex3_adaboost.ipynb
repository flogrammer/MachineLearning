{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "data_values = dataframe.values # 768 samples, 9 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_values)\n",
    "print(data_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_matrix = data_values[:,0:8]\n",
    "labels = data_values[:,8]\n",
    "\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_features = feature_matrix[:450]\n",
    "train_labels = labels[:450]\n",
    "\n",
    "test_features = feature_matrix[450:]\n",
    "test_labels = labels[450:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=9, min_samples_leaf=1)\n",
    "clf.fit(train_features,train_labels)\n",
    "clf_error_train = clf.score(train_features, train_labels)\n",
    "clf_error_test = clf.score(test_features,test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_rate(pred, Y):\n",
    "    return sum(pred != Y) / float(len(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_error_rate(er_train, er_test):\n",
    "    df_error = pd.DataFrame([er_train, er_test]).T\n",
    "    df_error.columns = ['Training', 'Test']\n",
    "    plot1 = df_error.plot(linewidth = 3, figsize = (8,6),\n",
    "            color = ['lightblue', 'darkblue'], grid = True)\n",
    "    plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
    "    plot1.set_xticklabels(range(0,450,50))\n",
    "    plot1.set_ylabel('Error rate', fontsize = 12)\n",
    "    plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
    "    plt.axhline(y=er_test[0], linewidth=1, color = 'red', ls = 'dashed')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#EXCERSICE 2\n",
    "#Implement the adaboost algorithm\n",
    "def adaboost_clf(train_features, train_labels, test_features, test_labels, M, clf):\n",
    "    n_train, n_test = len(train_features), len(test_features)\n",
    "    # Set initial weights\n",
    "    w = #INSERT\n",
    "    pred_train, pred_test = #INSERT\n",
    "    \n",
    "    # Step 1 / 6\n",
    "    for i in range(M):\n",
    "        # Step 2 \n",
    "        # Fit a classifier with the specific weights\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        \n",
    "        # Step 3\n",
    "        # Indicator function which represents the missclassification of weak classifier\n",
    "        miss = 0\n",
    "        # Equivalent with 1/-1 to update weights\n",
    "        miss2 = 0\n",
    "        # Error\n",
    "        err_m = 0\n",
    "        # Step 4\n",
    "        # Alpha\n",
    "        alpha_m = 0\n",
    "        # Step 5\n",
    "        # New weights\n",
    "        w = 0\n",
    "        \n",
    "        # Ergebnis: \n",
    "        # Add to prediction\n",
    "        pred_train = []\n",
    "        pred_test = []\n",
    "    \n",
    "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
    "    # Return error rate in train and test set\n",
    "    return get_error_rate(pred_train, train_labels), \\\n",
    "           get_error_rate(pred_test, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "er_train, er_test = [clf_error_train], [clf_error_test]\n",
    "# Fit Adaboost classifier using a decision tree as base estimator\n",
    " # Test with different number of iterations\n",
    "x_range = range(10, 410, 10)\n",
    "for i in x_range:    \n",
    "        er_i = adaboost_clf(train_features, train_labels, test_features, test_labels, i, clf)\n",
    "        er_train.append(er_i[0])\n",
    "        er_test.append(er_i[1])\n",
    "    \n",
    "# Compare error rate vs number of iterations\n",
    "plot_error_rate(er_train, er_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
